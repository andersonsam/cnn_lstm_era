{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:cnn_lstm_era] *",
      "language": "python",
      "name": "conda-env-cnn_lstm_era-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "cnn_lstm_ERA5_basic.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpSKQJBp4doM",
        "colab_type": "text"
      },
      "source": [
        "# Weather --> CNN --> LSTM --> Streamflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuzqoXuU4doO",
        "colab_type": "text"
      },
      "source": [
        "# Preamble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a_42-5jMQC9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "017ef541-7e07-422d-b36d-7a0bc7b8d4a1"
      },
      "source": [
        "#check memory available for use\n",
        "\n",
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm() "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 26.3 GB  | Proc size: 153.1 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JhG8GcN4doP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "e9de14e1-51d9-4626-c112-d429c2b0a2dc"
      },
      "source": [
        "#first: are you working in colab?\n",
        "colab = 1\n",
        "\n",
        "if colab:\n",
        "    \n",
        "    #mount drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    \n",
        "    #define path to google drive data\n",
        "    dataPath = '/content/drive/My Drive/Colab Notebooks/T_P_F_pca_lstm/'\n",
        "\n",
        "    #download required libraries that are not already in colab\n",
        "    !pip install geopandas\n",
        "    \n",
        "else:\n",
        "    \n",
        "    dataPath = ''"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.6/dist-packages (0.6.3)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.7.0)\n",
            "Requirement already satisfied: pyproj in /usr/local/lib/python3.6/dist-packages (from geopandas) (2.4.2.post1)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from geopandas) (0.25.3)\n",
            "Requirement already satisfied: fiona in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.8.13)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (1.17.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2.6.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (0.5.0)\n",
            "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (7.0)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (19.3.0)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (1.12.0)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (2.5.0)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJBATEiN4doT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af963c17-d391-4230-a0f9-aa26e7d212f4"
      },
      "source": [
        "#import required libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#from netCDF4 import Dataset\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, LSTM, Flatten, TimeDistributed, Dropout, Input\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import Model, Sequential, regularizers\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import geopandas as gpd\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy import interpolate\n",
        "import time\n",
        "import seaborn as sns"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoiFk8354doW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define functions that we'll use\n",
        "\n",
        "def nse(y_obs, y_model):\n",
        "\n",
        "  \"\"\"\n",
        "  NSE = nse(y_obs, y_model)\n",
        "\n",
        "  y_obs, y_model --> these are arrays of the same length (1 x N or N x1) where N is the number of observations in time\n",
        "  \"\"\"\n",
        "\n",
        "  y_model = y_model.reshape((-1,1))\n",
        "  y_obs = y_obs.reshape((-1,1))\n",
        "  nse = 1 - np.sum((y_model - y_obs)**2) / np.sum((y_obs - np.mean(y_obs))**2)\n",
        "  return nse\n",
        "\n",
        "def nse_rolling(y_obs, y_model, window, stride = 1):\n",
        "\n",
        "  \"\"\"\n",
        "  NSE_rolling = nse_rolling(y_obs, y_model, window, stride)\n",
        "\n",
        "  y_obs, y_model --> these are arrays of the same length (1 x N or N x 1) where N is the number of observations in time\n",
        "  window --> this is the length of time over which to compute NSE, which will roll accross the total time period\n",
        "  stride --> default stride = 1; length of step to take when rolling (i.e. stride = 365 computes yearly NSE with no overlap)\n",
        "  \"\"\"\n",
        "\n",
        "  NSE_rolling = []\n",
        "\n",
        "  y_model = y_model.reshape((-1,1))\n",
        "  y_obs = y_obs.reshape((-1,1))\n",
        "\n",
        "  startInds = range(0, len(y_model) - window, stride)\n",
        "  for startInd in startInds:\n",
        "    y_model_window = y_model[startInd:startInd+window] \n",
        "    y_obs_window = y_obs[startInd:startInd+window]\n",
        "    NSE = nse(y_obs_window, y_model_window)\n",
        "    NSE_rolling.append(NSE)\n",
        "\n",
        "  return NSE_rolling\n",
        "\n",
        "def plot_AB(prov='AB'):\n",
        "\n",
        "    \"\"\"\n",
        "    plot borders of alberta\n",
        "    \n",
        "    example:\n",
        "    import geopandas as gpd\n",
        "    import matplotlib.pyplot as plt\n",
        "    plot_AB()\n",
        "    plt.show()\n",
        "    \"\"\"\n",
        "    \n",
        "    provIndex=0\n",
        "    provshapes_filename = '/content/drive/My Drive/Colab Notebooks/cnn_lstm_era/PROVINCE.SHP'\n",
        "    provshapes = gpd.read_file(provshapes_filename)\n",
        "    provPoly = provshapes['geometry'][provIndex]\n",
        "    lonBorder,latBorder = provPoly.exterior.coords.xy \n",
        "\n",
        "    plt.plot(lonBorder,latBorder,'k')\n",
        "\n",
        "def rmse(target,prediction):\n",
        "  \"\"\" RMSE = rmse(target,prediction) \"\"\"\n",
        "\n",
        "  return(np.sqrt(((target.reshape(-1,1) - prediction.reshape(-1,1))**2).sum()/len(target.reshape(-1,1))))\n",
        "\n",
        "def rmse_group(*args):\n",
        "  rmse_group = []\n",
        "  for arg in args:\n",
        "    for other_arg in args:\n",
        "      rmse_group.append(rmse(arg,other_arg))\n",
        "\n",
        "  rmse_group = np.mean(rmse_group)\n",
        "\n",
        "  return rmse_group"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRjFBB8W4doa",
        "colab_type": "text"
      },
      "source": [
        "# Load data and preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gb77uvKc4dob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load data\n",
        "\n",
        "pickle_in = open(dataPath + 'flowDict.pickle','rb')\n",
        "flowDict = pickle.load(pickle_in)\n",
        "\n",
        "pickle_in = open(dataPath + 'tempDict_ERA5.pickle','rb')\n",
        "tempDict = pickle.load(pickle_in)\n",
        "\n",
        "pickle_in = open(dataPath + 'precDict_ERA5.pickle','rb')\n",
        "precDict = pickle.load(pickle_in)\n",
        "\n",
        "pickle_in = open(dataPath + 'spcHDict_ERA5.pickle','rb')\n",
        "spcHDict = pickle.load(pickle_in)\n",
        "\n",
        "pickle_in = open(dataPath + 'ssrdDict_ERA5.pickle','rb')\n",
        "ssrdDict = pickle.load(pickle_in)\n",
        "\n",
        "#unpack data\n",
        "\n",
        "stationLat = flowDict['stationLat']\n",
        "stationLon = flowDict['stationLon']\n",
        "eraLat = tempDict['latERA']\n",
        "eraLon = tempDict['lonERA']\n",
        "\n",
        "flowDays = flowDict['windowDays']\n",
        "flowMonths = flowDict['windowMonths']\n",
        "flowYears = flowDict['windowYears']\n",
        "eraDays = tempDict['daysERA']\n",
        "eraMonths = tempDict['monthsERA']\n",
        "eraYears = tempDict['yearsERA']\n",
        "\n",
        "F = flowDict['all_flowwindow_norm_NF'] #normalized discharge with nans filled (NF)\n",
        "T = tempDict['T']\n",
        "Tmax = tempDict['Tmax']\n",
        "Tmin = tempDict['Tmin']\n",
        "P = precDict['P']\n",
        "H = spcHDict['H']\n",
        "S = ssrdDict['S']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WCWz4oFDmW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del flowDict, tempDict, precDict, spcHDict, ssrdDict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5UWdcBY4doe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#set nan values to mean values of field (ie: out of province values\n",
        "\n",
        "meanT = np.nanmean(T)\n",
        "meanTmax = np.nanmean(Tmax)\n",
        "meanTmin = np.nanmean(Tmin)\n",
        "meanP = np.nanmean(P)\n",
        "meanH = np.nanmean(H)\n",
        "meanS = np.nanmean(S)\n",
        "\n",
        "Tall = np.copy(T)\n",
        "Tall[np.where(np.isnan(Tall))] = np.nanmean(T)\n",
        "T = Tall\n",
        "\n",
        "Tmaxall = np.copy(Tmax)\n",
        "Tmaxall[np.where(np.isnan(Tmaxall))] = np.nanmean(Tmax)\n",
        "Tmax = Tmaxall\n",
        "\n",
        "Tminall = np.copy(Tmin)\n",
        "Tminall[np.where(np.isnan(Tminall))] = np.nanmean(Tmin)\n",
        "Tmin = Tminall\n",
        "\n",
        "Pall = np.copy(P)\n",
        "Pall[np.where(np.isnan(Pall))] = np.nanmean(P)\n",
        "P = Pall\n",
        "\n",
        "Hall = np.copy(H)\n",
        "Hall[np.where(np.isnan(Hall))] = np.nanmean(H)\n",
        "H = Hall\n",
        "\n",
        "Sall = np.copy(S)\n",
        "Sall[np.where(np.isnan(Sall))] = np.nanmean(S)\n",
        "S = Sall"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRsTfhfxTIsp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#select subset of stations?\n",
        "\n",
        "customStations = 1\n",
        "\n",
        "if customStations:\n",
        "\n",
        "  stationInds = np.array([18,19,34,35,59,60,61,64,69,102,103,104,106,107,127,150,163,176]) - 1\n",
        "  stationInds = np.array([1,2,3,9,13,26,27,41,49,62,68,76,77,78,86,120,130,131,132,134,167,18,19,34,35,59,60,61,64,69,102,103,104,106,107,127,150,163,176])-1 #these are the stations with a record > 90 years, mean flow > 1 m^3/s\n",
        "  stationInds = np.array([2,13,27,41,62,78,86,120,131,132,134,167,19,35,59,60,61,64,102,103,106,107,127,150,163,176]) - 1 #these are the stations with a record > 90 years, mean flow > 1 m^3/s, fewest nans\n",
        "  stationInds = np.array([2,13,27,62,86,120,132,134,167,19,35,59,60,64,102,103,106,107,127,150,163,176]) - 1 #these are the stations with a record > 90 years, mean flow > 1 m^3/s, fewest nans, and don't have a min flow close to zero\n",
        "  stationInds = np.array([19,35,59,60,64,102,103,106,107,127,163,176]) - 1 #these are the stations with a record > 90 years, mean flow > 1 m^3/s, fewest nans, and don't have a min flow close to zero\n",
        "  F = np.asarray(F)\n",
        "  F = np.transpose(np.squeeze(F[stationInds]))\n",
        "\n",
        "else:\n",
        "\n",
        "  stationInds = np.arange(0,194,1)\n",
        "  F = np.asarray(np.transpose(np.squeeze(F[indStartFlow:])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt4EV44L4doh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#make data have same time range\n",
        "startYear = max(int(np.min(eraYears)),int(np.min(flowYears)))\n",
        "finYear = min(int(np.max(eraYears)),int(np.max(flowYears)))\n",
        "\n",
        "indStartERA = min(np.argwhere(eraYears==startYear))[0]\n",
        "indStartFlow = min(np.argwhere(flowYears==startYear))[0]\n",
        "\n",
        "indFinERA = max(np.argwhere(eraYears==finYear))[0]\n",
        "indFinFlow = max(np.argwhere(flowYears==finYear))[0]\n",
        "\n",
        "F = F[indStartFlow:indFinFlow]\n",
        "T = np.asarray(T[indStartERA:indFinERA])\n",
        "Tmax = np.asarray(Tmax[indStartERA:indFinERA])\n",
        "Tmin = np.asarray(Tmin[indStartERA:indFinERA])\n",
        "P = np.asarray(P[indStartERA:indFinERA])\n",
        "H = np.asarray(H[indStartERA:indFinERA])\n",
        "S = np.asarray(S[indStartERA:indFinERA])\n",
        "\n",
        "flowDays = flowDays[indStartFlow:indFinFlow]\n",
        "flowMonths = flowMonths[indStartFlow:indFinFlow]\n",
        "flowYears = flowYears[indStartFlow:indFinFlow]\n",
        "\n",
        "eraDays = eraDays[indStartERA:indFinERA]\n",
        "eraMonths = eraMonths[indStartERA:indFinERA]\n",
        "eraYears = eraYears[indStartERA:indFinERA]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgJaFjkS-rV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reduce spatial extent to only bound the stations of interest (reduce memory requirements)\n",
        "\n",
        "minLon = np.min(stationLon[stationInds])\n",
        "maxLon = np.max(stationLon[stationInds])\n",
        "minLat = np.min(stationLat[stationInds])\n",
        "maxLat = np.max(stationLat[stationInds])\n",
        "\n",
        "indMinLonERA = np.argmin(np.abs(eraLon - minLon))\n",
        "indMaxLonERA = np.argmin(np.abs(eraLon - maxLon))\n",
        "indMinLatERA = np.argmin(np.abs(eraLat - minLat))\n",
        "indMaxLatERA = np.argmin(np.abs(eraLat - maxLat))\n",
        "\n",
        "T = T[:, indMaxLatERA:indMinLatERA, indMinLonERA:indMaxLonERA]\n",
        "Tmax = Tmax[:, indMaxLatERA:indMinLatERA, indMinLonERA:indMaxLonERA]\n",
        "Tmin = Tmin[:, indMaxLatERA:indMinLatERA, indMinLonERA:indMaxLonERA]\n",
        "P = P[:, indMaxLatERA:indMinLatERA, indMinLonERA:indMaxLonERA]\n",
        "H = H[:, indMaxLatERA:indMinLatERA, indMinLonERA:indMaxLonERA]\n",
        "S = S[:, indMaxLatERA:indMinLatERA, indMinLonERA:indMaxLonERA]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9tEPp3L4dok",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d36d998b-af1f-479e-8e96-a1c6500f9035"
      },
      "source": [
        "print(np.shape(F),np.shape(T),np.shape(P),np.shape(H),np.shape(S))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8765, 12) (8765, 18, 24) (8765, 18, 24) (8765, 18, 24) (8765, 18, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3Ol-F6GFTDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCcY75XZBUi7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "1106d743-2bf1-49ae-822e-5ba9948bb5bf"
      },
      "source": [
        "extentERA = [minLon,maxLon,minLat,maxLat]\n",
        "\n",
        "plt.figure(figsize = (6,8))\n",
        "plot_AB()\n",
        "plt.imshow(T[0],aspect='auto',extent = extentERA, cmap = 'RdBu_r')\n",
        "plt.scatter(stationLon[stationInds],stationLat[stationInds], facecolor = 'w', edgecolor = 'k', s = 75)\n",
        "plt.title('Study Domain',fontsize = 20)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAHnCAYAAAChegbEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCSgFuIhIQP1/F/Bx/56A7jIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVTbUGuU4dom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prep data: standardize\n",
        "\n",
        "#indices of testing/training\n",
        "trainStartYear = 1987\n",
        "trainFinYear = 2005\n",
        "testStartYear = 2006\n",
        "testFinYear = 2010\n",
        "\n",
        "trainInds = np.squeeze(np.argwhere((flowYears>=trainStartYear) & (flowYears<=trainFinYear)))\n",
        "testInds = np.squeeze(np.argwhere((flowYears>=testStartYear) & (flowYears<=testFinYear)))\n",
        "\n",
        "#standardize variables individually (normalize wrt training period), then save as 32-bit rather than 64-bit for space\n",
        "Tmean_train = np.mean([T[trainInds[ii]] for ii in range(len(trainInds))])\n",
        "Tstd_train = np.std([T[trainInds[ii]] for ii in range(len(trainInds))])\n",
        "Tnorm = (T - Tmean_train)/Tstd_train\n",
        "Tnorm = np.single(Tnorm)\n",
        "\n",
        "Tmaxmean_train = np.mean([Tmax[trainInds[ii]] for ii in range(len(trainInds))])\n",
        "Tmaxstd_train = np.std([Tmax[trainInds[ii]] for ii in range(len(trainInds))])\n",
        "Tmaxnorm = (Tmax - Tmaxmean_train)/Tmaxstd_train\n",
        "Tmaxnorm = np.single(Tmaxnorm)\n",
        "\n",
        "Tminmean_train = np.mean([Tmin[trainInds[ii]] for ii in range(len(trainInds))])\n",
        "Tminstd_train = np.std([Tmin[trainInds[ii]] for ii in range(len(trainInds))])\n",
        "Tminnorm = (Tmin - Tminmean_train)/Tminstd_train\n",
        "Tminnorm = np.single(Tnorm)\n",
        "\n",
        "Pmean_train = np.mean([P[trainInds[ii]] for ii in range(len(trainInds))])\n",
        "Pstd_train = np.std([P[trainInds[ii]] for ii in range(len(trainInds))])\n",
        "Pnorm = (P - Pmean_train)/Pstd_train\n",
        "Pnorm = np.single(Pnorm)\n",
        "\n",
        "Hmean_train = np.mean([H[trainInds[ii]] for ii in range(len(trainInds))])\n",
        "Hstd_train = np.std([H[trainInds[ii]] for ii in range(len(trainInds))])\n",
        "Hnorm = (H - Hmean_train)/Hstd_train\n",
        "Hnorm = np.single(Hnorm)\n",
        "\n",
        "Smean_train = np.mean([S[trainInds[ii]] for ii in range(len(trainInds))])\n",
        "Sstd_train = np.std([S[trainInds[ii]] for ii in range(len(trainInds))])\n",
        "Snorm = (S - Smean_train)/Sstd_train\n",
        "Snorm = np.single(Snorm)\n",
        "\n",
        "##Fmean_train = np.nanmean([F[ii][trainInds[366:]] for ii in range(len(F))])\n",
        "##Fstd_train = np.nanstd([F[ii][trainInds[366:]] for ii in range(len(F))])\n",
        "#Fmean_train = np.mean(F[trainInds[366:],:])\n",
        "#Fstd_train = np.std(F[trainInds[366:],:])\n",
        "#Fnorm = (F - Fmean_train)/Fstd_train\n",
        "#Fnorm = np.single(Fnorm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxJHvfiY4dop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#normalize flow\n",
        "\n",
        "Fnorm = np.empty_like(F)\n",
        "for station in range(np.shape(F)[1]):\n",
        "    #F[:,station] = (F[:,station] - np.mean(F[:,station]))/np.std(F[:,station])\n",
        "    minF = np.min(F[:,station])\n",
        "    maxF = 2 * np.std(F[:,station])\n",
        "    Fnorm[:,station] = (F[:,station] - minF) / (maxF - minF)\n",
        "    \n",
        "#for inds in np.argwhere(F>10):\n",
        "#  F[inds[0],inds[1]] = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3WG8zvd4dot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#construct train and test predictor/target tensors\n",
        "\n",
        "#target data\n",
        "#y_train = np.squeeze([Fnorm[366:len(trainInds)+366,ii] for ii in range(np.shape(Fnorm)[1])])\n",
        "#y_test = np.squeeze([Fnorm[testInds[1:],ii] for ii in range(np.shape(Fnorm)[1])])\n",
        "#target data\n",
        "y_train = np.squeeze([Fnorm[365:trainInds[-1]+1,ii] for ii in range(np.shape(F)[1])]).T\n",
        "y_test = np.squeeze([Fnorm[testInds,ii] for ii in range(np.shape(F)[1])]).T\n",
        "y = np.empty((len(y_train[:,0])+len(y_test[:,0]),np.shape(F)[1])).T\n",
        "y[:,:len(y_train[:,0])] = y_train.T\n",
        "y[:,len(y_train[:,0]):] = y_test.T\n",
        "y = y.T\n",
        "\n",
        "#first, make (n_time x n_lon x n_lat x n_vars) tensor \n",
        "#x_intermediate = np.zeros((8766,17,43,2))\n",
        "nchannels = 3\n",
        "x_intermediate = np.empty(np.shape(Tmaxnorm) + (nchannels,),dtype=np.float16)#'single')\n",
        "x_intermediate[:,:,:,0] = Tmaxnorm\n",
        "x_intermediate[:,:,:,1] = Tminnorm\n",
        "x_intermediate[:,:,:,2] = Pnorm\n",
        "#x_intermediate[:,:,:,3] = Hnorm\n",
        "#x_intermediate[:,:,:,4] = Snorm\n",
        "x_train_intermediate = x_intermediate[trainInds]\n",
        "x_test_intermediate = x_intermediate[testInds]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tysSi1Ci4dov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#now, convert x_intermediate into (n_time x 365 x n_lon x n_lat x n_vars) tensor\n",
        "#x = np.zeros((8765-365,365,45,41,5),dtype='single')\n",
        "x_train = np.empty((len(trainInds) - 365, 365,) + np.shape(Tmaxnorm)[1:] + (nchannels,),dtype=np.float16)\n",
        "x_test = np.empty((len(testInds), 365,) + np.shape(Tmaxnorm)[1:] + (nchannels,),dtype=np.float16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JEECQyReGa86",
        "colab": {}
      },
      "source": [
        "for ii in range(1000):\n",
        "    x_train[ii] = x_intermediate[ii:ii+365]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vC7SsmlDGa89",
        "colab": {}
      },
      "source": [
        "for ii in range(1000,2000):\n",
        "    x_train[ii] = x_intermediate[ii:ii+365]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i2G5qpeU7iIf",
        "colab": {}
      },
      "source": [
        "for ii in range(2000,3000):\n",
        "    x_train[ii] = x_intermediate[ii:ii+365]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T9gQXQAk7iIh",
        "colab": {}
      },
      "source": [
        "for ii in range(3000,4000):\n",
        "    x_train[ii] = x_intermediate[ii:ii+365]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xYq9vC5d7iIj",
        "colab": {}
      },
      "source": [
        "for ii in range(4000,len(trainInds)-365):\n",
        "    x_train[ii] = x_intermediate[ii:ii+365]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NPYCij1V7iIl",
        "colab": {}
      },
      "source": [
        "for ii in range(1000):\n",
        "    x_test[ii] = x_intermediate[ii+len(trainInds)-365:ii+len(trainInds)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "auRmmJ0c7iIn",
        "colab": {}
      },
      "source": [
        "for ii in range(1000,2000):\n",
        "    x_test[ii] = x_intermediate[ii+len(trainInds)-365:ii+len(trainInds)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1-Db6_wF_3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for ii in range(1000,len(testInds)):\n",
        "    x_test[ii] = x_intermediate[ii+len(trainInds)-365:ii+len(trainInds)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1Gr_E1lu7iIp",
        "colab": {}
      },
      "source": [
        "for ii in range(2000,len(testInds)-1):\n",
        "    x_test[ii] = x_intermediate[ii+len(trainInds)-365:ii+len(trainInds)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJPV7n604dpC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "0e66af52-fac5-42a6-f0c7-f3deb1ee84b0"
      },
      "source": [
        "#CNN model\n",
        "print('Building model...')\n",
        "\n",
        "learning_rate = 0.0001\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(TimeDistributed(\n",
        "    Conv2D(filters = 8, kernel_size = (3,3), activation='relu',data_format='channels_last', padding='same'), \n",
        "    input_shape=(365,)+np.shape(Tnorm[0])+(nchannels,)))\n",
        "\n",
        "model.add(TimeDistributed(\n",
        "    Conv2D(filters = 8, kernel_size = (3,3), activation='relu',data_format='channels_last', padding='same'), \n",
        "    input_shape=(365,)+np.shape(Tnorm[0])+(nchannels,)))\n",
        "\n",
        "model.add(TimeDistributed(MaxPooling2D(pool_size = 2)))\n",
        "\n",
        "model.add(TimeDistributed(\n",
        "    Conv2D(filters = 16, kernel_size = (2,2), activation='relu',data_format='channels_last', padding='same'), \n",
        "    ))\n",
        "\n",
        "model.add(TimeDistributed(\n",
        "    Conv2D(filters = 16, kernel_size = (2,2), activation='relu',data_format='channels_last', padding='same'), \n",
        "    ))\n",
        "\n",
        "model.add(TimeDistributed(MaxPooling2D(pool_size = 2)))\n",
        "\n",
        "#model.add(TimeDistributed(\n",
        "#    Conv2D(filters = 32, kernel_size = (2,2), activation='relu',data_format='channels_last', padding='same'), \n",
        "#    ))\n",
        "#\n",
        "#model.add(TimeDistributed(\n",
        "#    Conv2D(filters = 32, kernel_size = (2,2), activation='relu',data_format='channels_last', padding='same'), \n",
        "#    ))\n",
        "\n",
        "#model.add(TimeDistributed(MaxPooling2D(pool_size = 2)))\n",
        "\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "model.add(Dropout(rate = 0.2))\n",
        "\n",
        "#LSTM model with time-distributed CNN as input\n",
        "#model.add(LSTM(units = 40, activation='tanh', recurrent_activation='hard_sigmoid', \n",
        "#               use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', \n",
        "#               bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, \n",
        "#               recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, \n",
        "#               kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, implementation=1, \n",
        "#               return_sequences=True, return_state=False))\n",
        "#model.add(LSTM(units = 40, activation='tanh', recurrent_activation='hard_sigmoid', \n",
        "#               use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', \n",
        "#               bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, \n",
        "#               recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, \n",
        "#               kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, implementation=1, \n",
        "#               return_sequences=False, return_state=False))\n",
        "#model.add(Dense(194, activation = 'relu'))\n",
        "\n",
        "model.add(LSTM(40, return_sequences=True))\n",
        "model.add(Dropout(rate=0.2))\n",
        "#model.add(LSTM(20, return_sequences=True))\n",
        "#model.add(Dropout(rate=0.1))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(np.shape(Fnorm)[1], activation = 'linear'))\n",
        "\n",
        "#compile\n",
        "print('Compiling model...')\n",
        "model.compile(loss=tensorflow.keras.losses.MSE,\n",
        "              optimizer=tensorflow.keras.optimizers.Adam(lr=learning_rate),\n",
        "              )\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', \n",
        "                   mode = 'min',\n",
        "                   verbose = 1, \n",
        "                   patience = 3,\n",
        "                   restore_best_weights = True)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building model...\n",
            "Compiling model...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "time_distributed (TimeDistri (None, 365, 18, 24, 8)    224       \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 365, 18, 24, 8)    584       \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 365, 9, 12, 8)     0         \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 365, 9, 12, 16)    528       \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, 365, 9, 12, 16)    1040      \n",
            "_________________________________________________________________\n",
            "time_distributed_5 (TimeDist (None, 365, 4, 6, 16)     0         \n",
            "_________________________________________________________________\n",
            "time_distributed_6 (TimeDist (None, 365, 384)          0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 365, 384)          0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 365, 40)           68000     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 365, 40)           0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 14600)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 12)                175212    \n",
            "=================================================================\n",
            "Total params: 245,588\n",
            "Trainable params: 245,588\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7XOk1iGJOVZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cd79412b-3305-49af-8429-e56b33acd6d3"
      },
      "source": [
        "np.shape(x_train), np.shape(y_train), np.shape(x_test), np.shape(y_test)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6575, 365, 18, 24, 3), (6575, 12), (1825, 365, 18, 24, 3), (1825, 12))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh8_l4We4dpF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "790b3992-df85-4a46-bf2b-e1939efbf4ac"
      },
      "source": [
        "#train model\n",
        "\n",
        "trainModel = 1\n",
        "\n",
        "batch_size = 256\n",
        "epochs = 40\n",
        "\n",
        "if trainModel == 1:\n",
        "\n",
        "  history = model.fit(x_train,y_train, \n",
        "                      validation_split = 0.2,\n",
        "                      shuffle = True, \n",
        "                      epochs = epochs, \n",
        "                      batch_size = batch_size,\n",
        "                      verbose = 1)#, \n",
        "                      #callbacks = [es])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5260 samples, validate on 1315 samples\n",
            "Epoch 1/40\n",
            " 256/5260 [>.............................] - ETA: 1:09"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InternalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-4a5ec116a453>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m                       \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                       \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                       verbose = 1)#, \n\u001b[0m\u001b[1;32m     15\u001b[0m                       \u001b[0;31m#callbacks = [es])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInternalError\u001b[0m:  dnn PoolForward launch failed\n\t [[node sequential/time_distributed_2/max_pooling2d/MaxPool (defined at <ipython-input-38-4a5ec116a453>:14) ]] [Op:__inference_distributed_function_3565]\n\nFunction call stack:\ndistributed_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UOUSJEp4dpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save model\n",
        "\n",
        "saveModel = 0\n",
        "glacierStations = 0\n",
        "\n",
        "if saveModel == 1:\n",
        "\n",
        "  if glacierStations == 1:\n",
        "    modelName = str(num_stations) + '_stations_' + 'CNN_LSTM_DENSE_glacierStations_' + str(epochs) + '_epochs'\n",
        "    model.save(modelName + '.h5')\n",
        "  else:\n",
        "    modelName = str(num_stations) + '_stations_' + 'CNN_LSTM_DENSE_' + str(epochs) + '_epochs'\n",
        "    model.save(modelName + '.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNOqXrAY4dpI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load model\n",
        "\n",
        "loadModel = 0\n",
        "\n",
        "if loadModel == 1:\n",
        "\n",
        "  dataPath = '/content/drive/My Drive/Colab Notebooks/cnn_lstm_era/'\n",
        "\n",
        "  if glacierStations == 1:\n",
        "    modelName = str(num_stations) + '_stations_' + 'CNN_LSTM_DENSE_glacierStations_' + str(epochs) + '_epochs'\n",
        "    model = load_model(dataPath + modelName + '.h5')\n",
        "  else:\n",
        "    modelName = str(num_stations) + '_stations_' + 'CNN_LSTM_DENSE_' + str(epochs) + '_epochs'\n",
        "    model = load_model(dataPath + modelName + '.h5')\n",
        "\n",
        "  #model = load_model(dataPath + str(num_stations) + '_stations_LSTM_DO_LSTM_DENSE.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgQDet9b4dpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_bulk = keras.models.clone_model(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zklAZ3NC4dpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot loss\n",
        "\n",
        "saveIt = 0\n",
        "\n",
        "if trainModel:\n",
        "\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "  epochs = range(1, len(loss) + 1)\n",
        "\n",
        "  plt.plot(loss, 'y', label='Training')\n",
        "  plt.plot(val_loss, 'r', label='Validation')\n",
        "  plt.title('Training and Validation Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  #plt.xlim((1,10))\n",
        "  #plt.ylim((0,.1))\n",
        "  #plt.show()\n",
        "\n",
        "  if saveIt:\n",
        "    plt.savefig('loss.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0T36HhS4dpO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#predict streamflow with trained model\n",
        "\n",
        "y_testPredict = model.predict(x_test, batch_size = 8192, verbose = 1)\n",
        "y_predict = model.predict(x, batch_size=8192, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btac4-si4dpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compute NSE\n",
        "\n",
        "obs_per_station_test = int(len(y_test)/num_stations)\n",
        "window = 366\n",
        "NSE = nse(y_test,y_testPredict)\n",
        "NSE_rolling = nse_rolling(y_test, y_testPredict, window, stride = 365)\n",
        "NSE_station = [nse(y_test[kk*obs_per_station_test:(kk+1)*obs_per_station_test], y_testPredict[kk*obs_per_station_test:(kk+1)*obs_per_station_test]) for kk in range(num_stations)]\n",
        "\n",
        "print('Overall NSE = ' + str(NSE)[:4])\n",
        "print('Mean Station NSE = ' + str(np.mean(NSE_station))[:4])\n",
        "print('Median Station NSE = ' + str(np.median(NSE_station))[:4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knYJHosV4dpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#visualize stations' performance\n",
        "\n",
        "sns.set(color_codes=True)\n",
        "sns.distplot(NSE_station, bins = 5)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOXdi23O4dpT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot model vs observed scatter plot\n",
        "\n",
        "saveIt = 0\n",
        "\n",
        "plt.figure(figsize = (8,8))\n",
        "\n",
        "plt.scatter(y_test, y_testPredict, alpha = 0.1)\n",
        "plt.xlabel('observation')\n",
        "plt.ylabel('model')\n",
        "plt.title('Model Results: NSE = ' + str(NSE)[:4])\n",
        "#plt.xlim((-2,5))\n",
        "#plt.xlim((0,4))\n",
        "#plt.yscale('log')\n",
        "#plt.xscale('log')\n",
        "\n",
        "if saveIt:\n",
        "  plt.savefig('obs_vs_model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_pB6NlP4dpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot time series of model and observations \n",
        "\n",
        "saveIt = 0\n",
        "\n",
        "plt.figure(figsize = (12,8))\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(y_test, label = 'Observed')\n",
        "plt.plot(y_testPredict, label = 'Modelled')\n",
        "plt.legend()\n",
        "plt.xlabel('Day')\n",
        "plt.ylabel('Normalized Streamflow')\n",
        "plt.title('Model Results: NSE = ' + str(NSE)[:4])\n",
        "plt.xlim((0,len(y_test)))\n",
        "plt.xlim((4*365*4,4*365*5))\n",
        "plt.ylim((0,3))\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "#plt.plot(range(int(window/2),len(y_test)-int(window/2)),NSE_rolling)\n",
        "plt.scatter(range(len(NSE_rolling)),NSE_rolling)\n",
        "plt.ylim((0,1))\n",
        "plt.xlim((0,len(NSE_rolling)))\n",
        "plt.xlim((15.5,19.5))\n",
        "plt.xlabel('Day')\n",
        "plt.ylabel('NSE')\n",
        "plt.title('Rolling NSE: Window = ' + str(window) + ' Days')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "if saveIt:\n",
        "  plt.savefig('modelled_time_series.png')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTYMSMY64dpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ2Ro7wC4dpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-TpJDvF4dpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}